# Project 2 – Titanic Dataset Analysis
**Name:** Lindsay Foster 
**Date:** 10/30/2025

## Introduction
The Titanic dataset contains information about passengers, including demographics, ticket information, and survival status. The goal of this project is to explore the dataset, analyze patterns, and apply basic machine learning techniques to predict survival.


# Steps

- Create the virtual environment

- Use Python’s built-in venv module: python -m venv .venv. .venv is the folder where your virtual environment will be stored.After this, your project folder will have a .venv directory.Tip: Use lowercase .venv (or venv) for convention. VS Code automatically recognizes .venv.

- Activate the virtual environment: .venv\Scripts\Activate.ps1. A requirements.txt lists all the Python packages your project needs so others (or you in a new environment) can install them easily with pip install -r requirements.txt.

### For Project 2 – Titanic Dataset Analysis, here’s a typical requirements.txt you can use:

pandas==2.2.0
numpy==1.26.0
matplotlib==3.8.1
seaborn==0.12.2
scikit-learn==1.3.2
jupyter==1.0.0
notebook==7.8.0

- How to use it - Save this file as requirements.txt in your project02 folder. Make sure your virtual environment is activated (.venv). Install all packages with:pip install -r requirements.txt.Select .venv as the kernel.Tell VS Code to use this .venv interpreter. Press Ctrl+Shift+P → type Python: Select Interpreter. Look for the interpreter in your .venv, e.g.:C:\Repos\project02\.venv\Scripts\python.exe. Select it. Reload VS Code to make sure it takes effect.This makes your editor aware of all packages installed in .venv.

## Project 2 – Titanic Dataset Analysis

### 2.1 Data Loading

- The dataset is loaded into a structured format that allows for easy inspection and analysis. Initial exploration helps us understand the columns available, the types of data, and any immediate patterns or anomalies in the dataset.

### 2.2 Handle Missing Values and Clean Data

- Age: Some passenger ages are missing. These missing values are imputed using the median age to maintain the overall distribution without skewing the data.

- Embark Town: A few entries for embarkation town are missing. These are filled using the mode (most common embarkation point) to ensure consistency.

- Other Data Cleaning: Additional columns with missing or irrelevant data are either imputed or removed to ensure the dataset is clean and ready for analysis.

- Reflection: Handling missing values carefully prevents bias in the model and ensures that the dataset remains representative of the original passengers.

### 2.3 Feature Engineering

- Family Size: A new feature family_size is created by summing the number of siblings/spouses and parents/children traveling with a passenger, plus one for the passenger themselves. This feature captures potential survival patterns related to traveling alone or in groups.

- Categorical Conversion: Categorical variables such as sex and embarked are converted to numeric values so that machine learning models can process them effectively.

- Alone Feature: A binary feature indicating whether a passenger is traveling alone is created, providing an additional signal that may correlate with survival.

- Reflection: Feature engineering is critical for improving model performance, as it introduces new information that may reveal hidden patterns in the data.

### 2.4 Exploratory Data Analysis (EDA)

- The dataset is visualized using summary statistics, histograms, boxplots, and countplots to identify trends and patterns.

- Relationships between features such as age, sex, family size, and survival are explored to inform feature selection and model building.

- Reflection: EDA provides insights into the factors influencing survival and helps guide decisions about which features to include in the model.

### 2.5 Data Preparation

- The dataset is split into features (inputs) and target (survival outcome).

- Data is further split into training and testing sets to evaluate model performance.

- Numeric scaling and categorical encoding are applied as needed to ensure the model receives standardized and meaningful inputs.

- Reflection: Proper data preparation ensures that the machine learning model can learn effectively and generalize well to unseen data.

### 2.6 Modeling and Evaluation

- A machine learning model, such as Logistic Regression, is trained using the prepared data.

- Model performance is evaluated using metrics like accuracy, confusion matrix, and classification reports to understand how well it predicts survival.

- Reflection: Evaluating the model on a separate test set helps assess its reliability and provides insight into potential areas for improvement.

## Section 3: Feature Selection and Justification
### 3.1 Choose Features and Target

- Target Variable: survived — indicates whether a passenger survived (1) or did not survive (0).

- This is the outcome we aim to predict using passenger information.

- Input Features:

    - Age: Passenger age may affect survival because children or seniors might have had different survival probabilities.

    - Fare: Ticket price often correlates with passenger class and access to lifeboats.

    - Pclass: Passenger class reflects socio-economic status and cabin location, historically impacting survival.

    - Sex: Gender strongly influenced survival, as women were prioritized during evacuation.

    - Family Size: Indicates whether a passenger traveled alone or with family; medium-sized families often had higher survival rates.

- Justification:

    - These features provide a mix of demographic, socio-economic, and relational information.

    - Historical patterns suggest that sex, class, and family-related features are highly predictive of survival.

    - Age and fare add nuanced information, improving the model’s ability to detect patterns.

### 3.2 Visual Analysis of Survival Patterns

- Sex:Female passengers had significantly higher survival rates than males. This aligns with the historical "women and children first" evacuation policy.

- Passenger Class (Pclass): First-class passengers had the highest survival rate, followed by second and third class. Higher socio-economic status likely provided better access to lifeboats.

- Family Size: Medium-sized families tended to survive more often than solo travelers or very large families.Traveling with a small family may have offered support during evacuation, while large families may have faced coordination difficulties.

- Age: Children and adults generally had better survival rates than seniors. Age influenced vulnerability and the likelihood of being assisted during the evacuation.

- Fare: Higher fares often corresponded to first-class passengers, reinforcing the class-survival correlation.

### 3.3 Reflection

- Why these features were selected: They capture the most relevant historical, demographic, and social factors affecting survival. Together, they provide a balanced view of each passenger’s situation.

- Most predictive features: Sex and Pclass are historically and statistically the strongest predictors. Family Size adds additional predictive power by showing relational context. Age and fare offer subtle but meaningful signals.

## Section 4: Train/Test Split and Class Balance
### 4.1 Train/Test Split

- The dataset was split into training (80%) and testing (20%) sets.

- The target variable for classification is survived.

- The split ensures that the model can learn patterns from the training data and be evaluated on unseen test data.

### 4.2 Class Distribution
- Dataset	Survived=0	Survived=1
- Original	61.6%	38.4%
- Train	61.1%	38.9%
- Test	63.7%	36.3%

- The training set closely matches the original dataset, maintaining representative proportions of survivors and non-survivors. The test set is slightly skewed toward non-survivors, but the difference is small.

### 4.3 Importance of Stratification

- Stratified splitting ensures that both training and test sets preserve the exact proportions of the target variable as in the original dataset. This prevents class imbalance in either subset, which can: Bias the model toward the majority class, Mislead evaluation metrics like accuracy or precision.

- For this dataset, stratification would produce a more reliable evaluation, especially because survival is not evenly distributed (61.6% vs. 38.4%).

### 4.4 Reflection

- The random split produced reasonably balanced sets, but the test set was slightly off from the original distribution.

- Using stratification would improve model reliability and ensure that performance metrics reflect the true underlying patterns in the data.

- Maintaining class balance is particularly important for classification tasks with imbalanced targets, like predicting Titanic survival.